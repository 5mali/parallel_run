# parallel_run
Execute inference in parallel in pytorch
